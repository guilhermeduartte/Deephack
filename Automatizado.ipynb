{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "sns.set()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unidecode\n",
    "\n",
    "def normalizeSentence(sentence):\n",
    "    \n",
    "    temp = sentence.split(' ')\n",
    "    new_sentence = []\n",
    "    for word in temp:\n",
    "        new_sentence.append(normalizeWord(word))\n",
    "    new_sentence = ' '.join(new_sentence)\n",
    "    \n",
    "    return new_sentence\n",
    "\n",
    "def normalizeWord(word):\n",
    "    \n",
    "    # lower case word\n",
    "    word = word.lower()\n",
    "    \n",
    "    # remove accents\n",
    "    word = unidecode.unidecode(word)\n",
    "    \n",
    "    return word\n",
    "\n",
    "def joinSeparetedWord(word):\n",
    "    \n",
    "    # removing aspas\n",
    "    word = word.split('\\'')\n",
    "    word = ''.join(word)\n",
    "    \n",
    "    # separete words from word\n",
    "    word = word.split()\n",
    "    \n",
    "    # join separeted words by '-'\n",
    "    word = '-'.join(word)\n",
    "    \n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selectByWord(word, sentences):\n",
    "    # select subset of sentences that contains word\n",
    "    # return indexs of sentences\n",
    "    \n",
    "    # normalize word\n",
    "    normalized_word = normalizeWord(word)\n",
    "    \n",
    "    indexs = []\n",
    "    \n",
    "    for i, sentence in enumerate(sentences):\n",
    "        # normalize sentence\n",
    "        normalized_sentence = normalizeSentence(sentence)\n",
    "        \n",
    "        if normalized_word in normalized_sentence:\n",
    "            #print(i, normalized_sentence)\n",
    "            indexs.append(i)\n",
    "    return indexs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selectDfRowsByWord(data, word, column):\n",
    "    '''\n",
    "    Select specific rows that contains especific word in the column\n",
    "    '''\n",
    "    \n",
    "    sentences = np.array(data[column].unique())\n",
    "\n",
    "    # find sentences\n",
    "    idxs = selectByWord(word, sentences)\n",
    "    obj_sentences = sentences[idxs]\n",
    "\n",
    "    servicos = pd.DataFrame()\n",
    "    for sentence in obj_sentences:\n",
    "\n",
    "        # select rows of exemplo\n",
    "        temp = data[data[column] == sentence]\n",
    "\n",
    "        # concatenate\n",
    "        servicos = pd.concat([servicos, temp])\n",
    "    try:\n",
    "        temp = len(servicos[column].unique())\n",
    "    except:\n",
    "        print(word + ': Not found')\n",
    "    \n",
    "    return servicos.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcDespesa(date, base, programa = None):\n",
    "    '''\n",
    "    Cálculo da despesa: empenhado - anulacao + reforco\n",
    "    date: [{year}, {month}]\n",
    "    base: pd.DataFrame\n",
    "    programa: {str}\n",
    "    '''\n",
    "    year = date[0]\n",
    "    month = date[1]\n",
    "    \n",
    "    temp = base.copy()\n",
    "    if programa is not None:\n",
    "        temp = base[base['ds_programa'] == programa].copy()\n",
    "    temp = temp[(temp['ano_exercicio'] == year) & (temp['mes_referencia'] == month)]\n",
    "    empenhado = temp[temp['tp_despesa'] == 'empenhado'].sum()\n",
    "    anulacao = temp[temp['tp_despesa'] == 'anulacao'].sum()\n",
    "    reforco = temp[temp['tp_despesa'] == 'reforco'].sum()\n",
    "    \n",
    "    del temp\n",
    "    return despesa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Municipio:\n",
    "    '''\n",
    "    \n",
    "    Município\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    def __init__(self, name, years = (2018, 2018), onlyAmbiental = False):\n",
    "        \n",
    "        self.keep_columns_ = ['ano_exercicio', 'mes_ref_extenso', 'mes_referencia', 'tp_despesa', 'vl_despesa',\n",
    "                              'ds_funcao_governo', 'ds_subfuncao_governo', 'ds_programa', 'ds_acao']\n",
    "        self.numeric_columns_ = ['ano_exercicio', 'vl_despesa', 'mes_referencia']\n",
    "        \n",
    "        self.years_ = np.arange(years[0], years[1]+1)\n",
    "        self.name_ = normalizeWord(name)\n",
    "        self.df_ = pd.DataFrame()\n",
    "        self.population_ = None\n",
    "        self.iamb_ = None\n",
    "        self.regiao_ = None\n",
    "        self.lat_ = None\n",
    "        self.long_ = None\n",
    "        self.onlyAmbiental_ = onlyAmbiental\n",
    "        print('Reading data...')\n",
    "        self.readData()\n",
    "        print('Preparing data...')\n",
    "        self.prepareData()\n",
    "        print('\\nBase for {} is ready!!'.format(self.name_))\n",
    "        \n",
    "    def readData(self):\n",
    "        \n",
    "        print('> reading population, i-Amb, lat, long...')\n",
    "        # reading population, i-amb...\n",
    "        \n",
    "        municipios_base = pd.read_csv('datasets/municipios.csv')\n",
    "        municipios = municipios_base['Município'].values\n",
    "        for i, municipio in enumerate(municipios):\n",
    "            if normalizeWord(self.name_) == normalizeWord(municipio):\n",
    "                self.population_ = municipios_base['Estimativa 2019'].values[i]\n",
    "                self.lat_ = municipios_base['Latitude'].values[i]\n",
    "                self.long_ = municipios_base['Longitude'].values[i]\n",
    "                self.iamb_ = municipios_base['i-Amb'].values[i]\n",
    "                self.regiao_ = municipios_base['Região Administrativa'].values[i]\n",
    "        if self.population_ is None:\n",
    "            print('Erro: population not found')\n",
    "            return\n",
    "        \n",
    "        print('> reading despesas...')\n",
    "        # reading despesas\n",
    "        \n",
    "        for year in self.years_:\n",
    "            print('>> year: '+str(year))\n",
    "            try:\n",
    "                aux = open('datasets/despesas/'+ str(year) +'/despesas-' + self.name_ + '-'+str(year)+'.csv', 'r')\n",
    "                aux.close()\n",
    "                del aux\n",
    "            except:\n",
    "                downloadDespesas([self.name_], year, unzip=True)\n",
    "            temp = pd.read_csv('datasets/despesas/'+ str(year) +'/despesas-' + self.name_ + '-'+str(year)+'.csv', sep = ';',  encoding = \"ISO-8859-1\")\n",
    "            temp = temp[self.keep_columns_]\n",
    "            self.df_ = pd.concat([self.df_, temp]).reset_index(drop = True)\n",
    "        del temp\n",
    "        \n",
    "    def prepareData(self):\n",
    "        \n",
    "        print('> removing NaN...')\n",
    "        # remove nan values\n",
    "        self.df_ = self.df_.dropna()\n",
    "        \n",
    "        # string para float\n",
    "        self.df_['vl_despesa'] = self.df_.vl_despesa.apply(lambda x : float('.'.join(x.split(','))))\n",
    "        \n",
    "        print('> normalizing words...')\n",
    "        # normalizando nome dos meses\n",
    "        for column in self.df_.columns:\n",
    "            if column in self.numeric_columns_:\n",
    "                 continue\n",
    "            self.df_[column] = self.df_[column].apply(lambda x : normalizeWord(x))\n",
    "        \n",
    "        self.df_['vl_despesa_per_capita'] = self.df_['vl_despesa'].apply(lambda x : x/self.population_)\n",
    "        \n",
    "        # ajsutando nomes com . no meio\n",
    "        for column in ['ds_programa', 'ds_acao']:\n",
    "            self.df_[column] = self.df_[column].apply(lambda x : ''.join(x.split('.')))\n",
    "            \n",
    "        # only gestao ambiental\n",
    "        if self.onlyAmbiental_:\n",
    "            self.df_ = self.df_[self.df_['ds_funcao_governo'] == 'gestao ambiental']\n",
    "        \n",
    "        \n",
    "    #def prepareSerie(self):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "import urllib.request\n",
    "import progressbar\n",
    "import os\n",
    "\n",
    "def downloadDespesas(names, year, unzip = False):\n",
    "        \n",
    "    n = len(names)\n",
    "    erros = []\n",
    "\n",
    "    for i in range(n):\n",
    "        name = names[i]\n",
    "\n",
    "        # uniformalizing word for match\n",
    "        name = normalizeWord(name)\n",
    "\n",
    "        # replacing ' ' to '-'\n",
    "        name = joinSeparetedWord(name)\n",
    "\n",
    "        # request download\n",
    "        url = 'https://transparencia.tce.sp.gov.br/sites/default/files/csv/despesas-' + name + '-' + str(year) + '.zip'\n",
    "        try:\n",
    "            zipName = 'downloads/' + name + '-' + str(year) + '.zip'\n",
    "            urllib.request.urlretrieve(url, zipName)\n",
    "            if unzip:\n",
    "                with ZipFile(zipName, 'r') as zipObj:\n",
    "                    zipObj.extractall('datasets/despesas/' + str(year))\n",
    "                try:\n",
    "                    os.rename('datasets/despesas/' + str(year) + '/despesas-' + name + '-' + str(year) + '.zip.csv', 'datasets/despesas/' + str(year) + '/despesas-' + name + '-' + str(year) + '.csv')\n",
    "                except:\n",
    "                    continue\n",
    "        except:\n",
    "            erros.append(name)\n",
    "        \n",
    "    if len(erros) == 0:\n",
    "        print('All files have been downloaded!')\n",
    "    else:\n",
    "        print('Files not found:')\n",
    "        print(erros)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "municipios = pd.read_csv('datasets/municipios.csv').set_index('Município')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "municipios_nomes = ['Caraguatatuba']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = municipios.loc[municipios_nomes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Posição</th>\n",
       "      <th>Estimativa 2019</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Região Administrativa</th>\n",
       "      <th>Porte</th>\n",
       "      <th>i-Amb</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Município</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Caraguatatuba</th>\n",
       "      <td>71</td>\n",
       "      <td>121532</td>\n",
       "      <td>-23.6125</td>\n",
       "      <td>-45.4125</td>\n",
       "      <td>Região Administrativa de São José dos Campos</td>\n",
       "      <td>Médio</td>\n",
       "      <td>B+</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Posição  Estimativa 2019  Latitude  Longitude  \\\n",
       "Município                                                      \n",
       "Caraguatatuba       71           121532  -23.6125   -45.4125   \n",
       "\n",
       "                                      Região Administrativa  Porte i-Amb  \n",
       "Município                                                                 \n",
       "Caraguatatuba  Região Administrativa de São José dos Campos  Médio    B+  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files not found:\n",
      "['caraguatatuba']\n"
     ]
    }
   ],
   "source": [
    "downloadDespesas(sample.index, unzip = True, year = 2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data...\n",
      "> reading population, i-Amb, lat, long...\n",
      "> reading despesas...\n",
      ">> year: 2014\n",
      "Files not found:\n",
      "['caraguatatuba']\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'datasets/despesas/2014/despesas-caraguatatuba-2014.csv' does not exist: b'datasets/despesas/2014/despesas-caraguatatuba-2014.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-7b0f07781e53>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mexemplo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMunicipio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'caraguatatuba'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myears\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2014\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2018\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-13-9da5e6ea61ab>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, years, onlyAmbiental)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monlyAmbiental_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0monlyAmbiental\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Reading data...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Preparing data...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepareData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-9da5e6ea61ab>\u001b[0m in \u001b[0;36mreadData\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m                 \u001b[0mdownloadDespesas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munzip\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m             \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'datasets/despesas/'\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m'/despesas-'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'-'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m';'\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"ISO-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m             \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtemp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeep_columns_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    683\u001b[0m         )\n\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1135\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1136\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1904\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1905\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1906\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1907\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'datasets/despesas/2014/despesas-caraguatatuba-2014.csv' does not exist: b'datasets/despesas/2014/despesas-caraguatatuba-2014.csv'"
     ]
    }
   ],
   "source": [
    "exemplo = Municipio('caraguatatuba', years = (2014, 2018))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "enumerate() missing required argument 'iterable' (pos 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-132-396d8ff886ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: enumerate() missing required argument 'iterable' (pos 1)"
     ]
    }
   ],
   "source": [
    "for i, item in enumerate():\n",
    "    print(i, type(item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exemplo.df_['ds_acao'].unique()[196]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
